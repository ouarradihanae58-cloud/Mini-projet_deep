# -*- coding: utf-8 -*-
"""miniprojet3.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1rS2GAiQFxE0ma7jYk6ukTH4DVHd_JyQ_
"""

import random, numpy as np
import torch
from torch import nn
from torch.utils.data import DataLoader
from torchvision import datasets, transforms
import matplotlib.pyplot as plt

def set_seed(seed=42):
    random.seed(seed)
    np.random.seed(seed)
    torch.manual_seed(seed)
    torch.cuda.manual_seed_all(seed)
    torch.backends.cudnn.deterministic = True
    torch.backends.cudnn.benchmark = False

set_seed(42)

device = "cuda" if torch.cuda.is_available() else "cpu"
print("Device:", device)

mean, std = 0.2860, 0.3530

train_transform = transforms.Compose([
    transforms.RandomHorizontalFlip(p=0.2),   # petite augmentation (safe)
    transforms.ToTensor(),
    transforms.Normalize((mean,), (std,))
])

test_transform = transforms.Compose([
    transforms.ToTensor(),
    transforms.Normalize((mean,), (std,))
])

train_ds = datasets.FashionMNIST(root="./data", train=True, download=True, transform=train_transform)
test_ds  = datasets.FashionMNIST(root="./data", train=False, download=True, transform=test_transform)

labels = ["T-shirt","Pantalon","Pull","Robe","Manteau","Sandale","Chemise","Basket","Sac","Bottine"]

# Visualisation du dataset (exemples)
plt.figure(figsize=(8, 8))

for i in range(9):
    x, y = train_ds[i]
    img = x.squeeze().numpy() * std + mean  # dé-normalisation
    plt.subplot(3, 3, i + 1)
    plt.imshow(img, cmap="gray")
    plt.title(labels[y])
    plt.axis("off")
    plt.suptitle("Exemples d'images du dataset FashionMNIST", fontsize=14)
plt.show()

# 2) Model: CNN simple & efficace
class SimpleCNN(nn.Module):
    def __init__(self):
        super().__init__()
        self.features = nn.Sequential(
            nn.Conv2d(1, 32, kernel_size=3, padding=1),  # 28x28
            nn.BatchNorm2d(32),
            nn.ReLU(),
            nn.MaxPool2d(2),                             # 14x14

            nn.Conv2d(32, 64, kernel_size=3, padding=1), # 14x14
            nn.BatchNorm2d(64),
            nn.ReLU(),
            nn.MaxPool2d(2),                             # 7x7

            nn.Conv2d(64, 128, kernel_size=3, padding=1),# 7x7
            nn.BatchNorm2d(128),
            nn.ReLU(),
        )
        self.classifier = nn.Sequential(
            nn.Flatten(),
            nn.Dropout(0.3),
            nn.Linear(128 * 7 * 7, 128),
            nn.ReLU(),
            nn.Dropout(0.2),
            nn.Linear(128, 10)
        )

    def forward(self, x):
        x = self.features(x)
        x = self.classifier(x)
        return x

model = SimpleCNN().to(device)

# 3) Fonction de perte, optimiseur et planificateur du taux d’apprentissage

loss_fn = nn.CrossEntropyLoss()
optimizer = torch.optim.Adam(model.parameters(), lr=1e-3, weight_decay=1e-4)
scheduler = torch.optim.lr_scheduler.StepLR(optimizer, step_size=5, gamma=0.5)

# 4) Fonctions d’aide pour les métriques
def accuracy(loader):
    model.eval()
    correct, total = 0, 0

    with torch.inference_mode():
        for x, y in loader:
            x, y = x.to(device), y.to(device)
            preds = model(x).argmax(dim=1)
            correct += (preds == y).sum().item()
            total += y.size(0)

    return correct / total

train_loader = DataLoader(
    train_ds,
    batch_size=128,
    shuffle=True,
    num_workers=2,
    pin_memory=True
)

test_loader = DataLoader(
    test_ds,
    batch_size=256,
    shuffle=False,
    num_workers=2,
    pin_memory=True
)

# 5) Boucle d’entraînement (sauvegarde du meilleur modèle)
epochs = 10
train_losses = []
best_test_acc = 0.0
best_state = None

for epoch in range(1, epochs+1):
    model.train()
    running_loss = 0.0

    for x, y in train_loader:
        x, y = x.to(device), y.to(device)

        optimizer.zero_grad(set_to_none=True)
        logits = model(x)
        loss = loss_fn(logits, y)
        loss.backward()
        optimizer.step()

        running_loss += loss.item() * y.size(0)

    scheduler.step()

    avg_loss = running_loss / len(train_loader.dataset)
    train_acc = accuracy(train_loader)
    test_acc  = accuracy(test_loader)
    train_losses.append(avg_loss)

    if test_acc > best_test_acc:
        best_test_acc = test_acc
        best_state = {k: v.detach().cpu().clone() for k, v in model.state_dict().items()}

    print(f"Epoch {epoch:02d} | Loss: {avg_loss:.4f} | Train acc: {train_acc:.4f} | Test acc: {test_acc:.4f} | Best test: {best_test_acc:.4f}")

# Restaurer le meilleur modèle
if best_state is not None:
    model.load_state_dict(best_state)
    model.to(device)
print("Best Test Accuracy:", best_test_acc)

# 6) Tracer la fonction de perte
plt.figure()
plt.plot(train_losses)
plt.xlabel("Epoch")
plt.ylabel("Loss")
plt.title("Training Loss")
plt.show()

#Visualisation et test d’une image de FashionMNIST
idx = 1
x, y_true = test_ds[idx]
x_batch = x.unsqueeze(0).to(device)

model.eval()
with torch.no_grad():
    y_pred = model(x_batch).argmax(dim=1).item()

# Dé-normalisation pour l’affichage
img = x.squeeze().cpu().numpy() * std + mean
plt.imshow(img, cmap="gray")
plt.title(f"Vrai: {labels[y_true]} | Prédit: {labels[y_pred]}")
plt.axis("off")
plt.show()

# 8) Image externe depuis Google Drive (optionnel)
from google.colab import drive
drive.mount('/content/drive')

import os
from PIL import Image

img_path = "/content/drive/MyDrive/sac.jpg"  # change si besoin
if not os.path.exists(img_path):
    raise FileNotFoundError(f"Image introuvable: {img_path} (vérifie le nom exact et le dossier)")

ext_transform = transforms.Compose([
    transforms.Grayscale(num_output_channels=1),
    transforms.Resize((28, 28)),
    transforms.ToTensor(),
    transforms.Lambda(lambda x: 1 - x)
])


img_pil = Image.open(img_path).convert("RGB")
img_tensor = ext_transform(img_pil)

# prédire
img_batch = img_tensor.unsqueeze(0).to(device)
model.eval()
with torch.no_grad():
    pred = model(img_batch).argmax(dim=1).item()

img_pil = Image.open(img_path).convert("RGB")
img_tensor = ext_transform(img_pil)

img_batch = img_tensor.unsqueeze(0).to(device)

model.eval()
with torch.inference_mode():
    pred = model(img_batch).argmax(dim=1).item()

plt.imshow(img_tensor.squeeze().cpu(), cmap="gray")
plt.title(f"Image externe | Prédit: {labels[pred]}")
plt.axis("off")
plt.show()

print("Le modèle prédit :", labels[pred])

import os
from PIL import Image
from torch.utils.data import Dataset, DataLoader
from torchvision import transforms

class FashionPNGDataset(Dataset):
    def __init__(self, root_dir, transform=None):
        self.root_dir = root_dir
        self.transform = transform
        self.img_paths = []
        self.labels = []

        # parcourir les sous-dossiers par classe
        classes = sorted(os.listdir(root_dir))
        for i, cls in enumerate(classes):
            cls_dir = os.path.join(root_dir, cls)
            for img_name in os.listdir(cls_dir):
                self.img_paths.append(os.path.join(cls_dir, img_name))
                self.labels.append(i)
        self.classes = classes

    def __len__(self):
        return len(self.img_paths)

    def __getitem__(self, idx):
        img = Image.open(self.img_paths[idx]).convert("L")  # convertir en gris
        label = self.labels[idx]
        if self.transform:
            img = self.transform(img)
        return img, label

transform = transforms.Compose([
    transforms.Resize((28,28)),          # taille compatible FashionMNIST
    transforms.ToTensor(),               # convertir en tenseur
    transforms.Normalize((0.286,), (0.353,))  # normalisation comme FashionMNIST
])

kaggle_test_root = "/content/drive/MyDrive/fashion_test/fashion_mnist_kaggle/fashion-mnist-png/test"
kaggle_test_ds = FashionPNGDataset(kaggle_test_root, transform=transform)
kaggle_test_loader = DataLoader(kaggle_test_ds, batch_size=256, shuffle=False)

subset_loader = DataLoader(
    torch.utils.data.Subset(kaggle_test_ds, range(500)),  # prendre seulement 500 images
    batch_size=256,
    shuffle=False
)

kaggle_acc = accuracy(subset_loader)
print("Accuracy sur un sous-ensemble de 500 images :", kaggle_acc)

import matplotlib.pyplot as plt
import numpy as np

model.eval()
plt.figure(figsize=(10,10))

for i in range(9):
    x, y_true = kaggle_test_ds[i]
    x_batch = x.unsqueeze(0).to(device)

    with torch.no_grad():
        y_pred = model(x_batch).argmax(dim=1).item()

    # dé-normaliser
    img = x.squeeze().cpu().numpy() * 0.353 + 0.286

    plt.subplot(3,3,i+1)
    plt.imshow(img, cmap='gray')

    # couleur du titre selon si correct ou pas
    color = 'green' if y_pred == y_true else 'red'

    plt.title(f"Vrai: {kaggle_test_ds.classes[y_true]}\nPrédit: {kaggle_test_ds.classes[y_pred]}", color=color)
    plt.axis('off')

plt.tight_layout()
plt.show()